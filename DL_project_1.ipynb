{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_project.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "XeSyyk9ys5FW",
        "colab_type": "code",
        "outputId": "44f649c5-72e2-49c1-827b-89c878ca11df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import librosa\n",
        "import glob\n",
        "import os\n",
        "import string\n",
        "import itertools\n",
        "import threading\n",
        "import codecs\n",
        "import unicodedata\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# In[3]:\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.DEBUG)\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# In[4]:\n",
        "\n",
        "# Constants\n",
        "SPACE_TOKEN = '<space>'\n",
        "SPACE_INDEX = 0\n",
        "FIRST_INDEX = ord('a') - 1  # 0 is reserved to space\n",
        "\n",
        "def text_to_char_array(original):\n",
        "    r\"\"\"\n",
        "    Given a Python string ``original``, remove unsupported characters, map characters\n",
        "    to integers and return a numpy array representing the processed string.\n",
        "    \"\"\"\n",
        "    # Create list of sentence's words w/spaces replaced by ''\n",
        "    result = ' '.join(original.translate(None, string.punctuation).lower().split())\n",
        "    result = result.replace(\" '\", \"\") # TODO: Deal with this properly\n",
        "    result = result.replace(\"'\", \"\")    # TODO: Deal with this properly\n",
        "    result = result.replace(' ', '  ')\n",
        "    result = result + ' ' #Append spaces at the end of files\n",
        "    result = result.split(' ')\n",
        "\n",
        "    # Tokenize words into letters adding in SPACE_TOKEN where required\n",
        "    result = np.hstack([SPACE_TOKEN if xt == '' else list(xt) for xt in result])\n",
        "    \n",
        "    # Map characters into indicies\n",
        "    result = np.asarray([SPACE_INDEX if xt == SPACE_TOKEN else ord(xt) - FIRST_INDEX for xt in result])\n",
        "    \n",
        "    # Add result to results\n",
        "    return result\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def _get_audio_feature_mfcc(wav_file):\n",
        "    #All wav files are with 8k sampling rate : Taking Fourier representation: 20 ms speech to 20 feature\n",
        "    sample_rate = 16000\n",
        "    # load wave file with sampling rate 8000 which is already known. sr value is important\n",
        "    data, sr = librosa.load(wav_file, mono=True, sr=sample_rate)\n",
        "\n",
        "    #Short First Fourier transform - for every 20 second for 8k sampling rate= 160\n",
        "    mfcc = librosa.feature.mfcc(data, sr=sample_rate, n_mfcc=20)\n",
        "    \n",
        "    return mfcc\n",
        "\n",
        "\n",
        "\n",
        "def _load_feature_and_label(src_list):\n",
        "    txt_file, wav_file = src_list \n",
        "    label = ''\n",
        "\n",
        "    with codecs.open(txt_file, encoding=\"utf-8\") as open_txt_file:\n",
        "        label = unicodedata.normalize(\"NFKD\", open_txt_file.read()).encode(\"ascii\", \"ignore\")\n",
        "        label = text_to_char_array(label)\n",
        "        label = label[8:]\n",
        "    label_len = len(label)\n",
        "\n",
        "    feature = _get_audio_feature_mfcc(wav_file)\n",
        "    feature_len = np.size(feature, 1)\n",
        "\n",
        "    # return result\n",
        "    return label, label_len, feature, feature_len\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# In[5]:\n",
        "\n",
        "###  ctc_label_dense_to_sparse and Taken from https://github.com/mozilla/DeepSpeech  ##########\n",
        "\n",
        "# gather_nd is taken from https://github.com/tensorflow/tensorflow/issues/206#issuecomment-229678962\n",
        "# \n",
        "# Unfortunately we can't just use tf.gather_nd because it does not have gradients\n",
        "# implemented yet, so we need this workaround.\n",
        "#\n",
        "def gather_nd(params, indices, shape):\n",
        "    rank = len(shape)\n",
        "    flat_params = tf.reshape(params, [-1])\n",
        "    multipliers = [reduce(lambda x, y: x*y, shape[i+1:], 1) for i in range(0, rank)]\n",
        "    indices_unpacked = tf.unstack(tf.transpose(indices, [rank - 1] + range(0, rank - 1)))\n",
        "    flat_indices = sum([a*b for a,b in zip(multipliers, indices_unpacked)])\n",
        "    return tf.gather(flat_params, flat_indices)\n",
        "\n",
        "# ctc_label_dense_to_sparse is taken from https://github.com/tensorflow/tensorflow/issues/1742#issuecomment-205291527\n",
        "#\n",
        "# The CTC implementation in TensorFlow needs labels in a sparse representation,\n",
        "# but sparse data and queues don't mix well, so we store padded tensors in the\n",
        "# queue and convert to a sparse representation after dequeuing a batch.\n",
        "\n",
        "def ctc_label_dense_to_sparse(labels, label_lengths, batch_size):\n",
        "    # The second dimension of labels must be equal to the longest label length in the batch\n",
        "    correct_shape_assert = tf.assert_equal(tf.shape(labels)[1], tf.reduce_max(label_lengths))\n",
        "    with tf.control_dependencies([correct_shape_assert]):\n",
        "        labels = tf.identity(labels)\n",
        "\n",
        "    label_shape = tf.shape(labels)\n",
        "    num_batches_tns = tf.stack([label_shape[0]])\n",
        "    max_num_labels_tns = tf.stack([label_shape[1]])\n",
        "    def range_less_than(previous_state, current_input):\n",
        "        return tf.expand_dims(tf.range(label_shape[1]), 0) < current_input\n",
        "\n",
        "    init = tf.cast(tf.fill(max_num_labels_tns, 0), tf.bool)\n",
        "    init = tf.expand_dims(init, 0)\n",
        "    dense_mask = tf.scan(range_less_than, label_lengths, initializer=init, parallel_iterations=1)\n",
        "    dense_mask = dense_mask[:, 0, :]\n",
        "\n",
        "    label_array = tf.reshape(tf.tile(tf.range(0, label_shape[1]), num_batches_tns),\n",
        "          label_shape)\n",
        "    label_ind = tf.boolean_mask(label_array, dense_mask)\n",
        "\n",
        "    batch_array = tf.transpose(tf.reshape(tf.tile(tf.range(0, label_shape[0]), max_num_labels_tns), tf.reverse(label_shape, [0])))\n",
        "    batch_ind = tf.boolean_mask(batch_array, dense_mask)\n",
        "\n",
        "    indices = tf.transpose(tf.reshape(tf.concat([batch_ind, label_ind], 0), [2, -1]))\n",
        "    shape = [batch_size, tf.reduce_max(label_lengths)]\n",
        "    vals_sparse = gather_nd(labels, indices, shape)\n",
        "    \n",
        "    return tf.SparseTensor(tf.to_int64(indices), vals_sparse, tf.to_int64(label_shape))\n",
        "\n",
        "\n",
        "# In[6]:\n",
        "\n",
        "\n",
        "#Input tensor sequence length calculation needed because of convolution changes the length\n",
        "#Take input as shape`[max_time, batch_size, feature]\n",
        "def get_seq_length(input_tensor):\n",
        "    n_items  = tf.slice(tf.shape(input_tensor), [1], [1])\n",
        "    n_steps = tf.slice(tf.shape(input_tensor), [0], [1])\n",
        "    seq_length = tf.tile(n_steps, n_items)\n",
        "    return seq_length\n",
        "\n",
        "\n",
        "#input_tensor is of shape `[max_time, batch_size, input_size]`.\n",
        "#Returns tensor of shape `[max_time, batch_size, input_size]`.\n",
        "def rnn_layer(input_tensor, n_cell_units, dropout, seq_length, batch_size):\n",
        "\n",
        "    lstm_fw_cell = tf.contrib.rnn.BasicLSTMCell(2*n_cell_units, forget_bias=1.0, state_is_tuple=True)\n",
        "    lstm_fw_cell = tf.contrib.rnn.DropoutWrapper(lstm_fw_cell, input_keep_prob=dropout, output_keep_prob=dropout)\n",
        "    \n",
        "    outputs, output_states = tf.nn.dynamic_rnn(cell=lstm_fw_cell, \n",
        "                                               inputs=input_tensor,\n",
        "                                               dtype=tf.float32, \n",
        "                                               time_major=True, \n",
        "                                               sequence_length=seq_length)\n",
        "    \n",
        "    return outputs\n",
        "\n",
        "\n",
        "# In[7]:\n",
        "\n",
        "\n",
        "#\n",
        "# hyper parameters\n",
        "#\n",
        "features_in_step = 20\n",
        "# The number of characters in the target language plus one ===>   (<space> + a-z + <one extra>)\n",
        "n_class = 28\n",
        "\n",
        "num_batch = 1\n",
        "num_epoch = 100\n",
        "batch_size = 1\n",
        "\n",
        "####Learning Parameters\n",
        "initial_learning_rate = 0.001\n",
        "momentum = 0.9\n",
        "\n",
        "#RNN Layer\n",
        "n_cell_units = 128\n",
        "dropout = 0.8\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# In[8]:\n",
        "\n",
        "tf.reset_default_graph()\n",
        "input_labels = tf.placeholder(tf.int32, shape=[batch_size,None])\n",
        "input_labels_length = tf.placeholder(tf.int32, shape=[batch_size])\n",
        "input_features = tf.placeholder(tf.float32, shape=[batch_size, features_in_step, None])\n",
        "\n",
        "\n",
        "weights = {\n",
        "    'wr1': tf.Variable(tf.random_normal([2*n_cell_units, n_class], mean=0.1, stddev=1.0))\n",
        "}\n",
        "\n",
        "biases = {\n",
        "    'br1': tf.Variable(tf.random_normal([n_class], mean=0.1, stddev=1.0))\n",
        "}\n",
        "\n",
        "conv_out = input_features\n",
        "\n",
        "#Convert the output to time major of shape`[max_time, batch_size, feature] for RNN layer input\n",
        "conv_out = tf.transpose(conv_out, perm=[2, 0, 1])\n",
        "\n",
        "seq_length = get_seq_length(conv_out)\n",
        "\n",
        "# RNN Layers\n",
        "\n",
        "rnn_output = rnn_layer(conv_out, n_cell_units, dropout, seq_length, batch_size)\n",
        "\n",
        "#Batch size x max_length x n_cell_units.\n",
        "####  This is dense layer for classification -- RNN \n",
        "#ctc network performs softmax layer. in your code, rnn layer is connected to ctc loss layer. \n",
        "#output of rnn layer is internally activated, \n",
        "#so need to add one more hidden layer(as output layer) without activation function, \n",
        "#then add ctc loss layer.\n",
        "prediction = tf.reshape(rnn_output, [-1, 2*n_cell_units])\n",
        "prediction = tf.add(tf.matmul(prediction, weights['wr1']), biases['br1'])\n",
        "prediction = tf.reshape(prediction, [batch_size, -1, n_class])\n",
        "prediction = tf.transpose(prediction, perm=[1, 0, 2])\n",
        "\n",
        "\n",
        "#CTC Layer\n",
        "#Dense to sparse vector conversion\n",
        "sparse_labels = ctc_label_dense_to_sparse(input_labels, input_labels_length, batch_size)\n",
        "\n",
        "#Train\n",
        "loss_from_ctc = tf.nn.ctc_loss(inputs=prediction, labels=sparse_labels, sequence_length=seq_length, time_major=True)\n",
        "loss = tf.reduce_mean(loss_from_ctc)\n",
        "optimizer = tf.train.MomentumOptimizer(initial_learning_rate, momentum).minimize(loss)\n",
        "\n",
        "\n",
        "#Accuracy Check\n",
        "decoded, _ = tf.nn.ctc_beam_search_decoder(inputs=prediction, sequence_length=seq_length, merge_repeated=False)\n",
        "accuracy = tf.reduce_mean(tf.edit_distance(tf.cast(decoded[0], tf.int32), sparse_labels))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# In[9]:\n",
        "\n",
        "np_input_labels, np_input_labels_length, np_input_features, np_input_features_length = _load_feature_and_label(['SA1.TXT','SA1.WAV'])\n",
        "\n",
        "np_input_labels = np.reshape(np_input_labels, (batch_size, -1))\n",
        "np_input_labels_length = np.reshape(np_input_labels_length, (batch_size))\n",
        "np_input_features = np.reshape(np_input_features, (batch_size, features_in_step, -1))\n",
        "np_input_features_length = np.reshape(np_input_features_length, (batch_size))\n",
        "\n",
        "print(np_input_features_length)\n",
        "print(np_input_labels_length)\n",
        "\n",
        "# In[10]:\n",
        "\n",
        "\n",
        "\n",
        "with tf.Session() as sess:\n",
        "\n",
        "  # initialize the variables\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "\n",
        "  print('Training')\n",
        "#     try:\n",
        "\n",
        "  feed = {input_labels: np_input_labels, input_labels_length: np_input_labels_length, input_features: np_input_features}\n",
        "\n",
        "  for epoch in xrange(num_epoch):\n",
        "      epoch_loss = 0\n",
        "      for step in xrange(num_batch):\n",
        "          print (sess.run([loss, accuracy], feed_dict=feed))\n",
        "          _, c = sess.run([optimizer, loss], feed)\n",
        "          print 'Epoch:', epoch ,'Step:', step, ' Loss:', c\n",
        "          epoch_loss += c\n",
        "      print 'Epoch:', epoch, ' AccLoss:', epoch_loss\n",
        "\n",
        "  print 'Finished.'\n",
        "#     except Exception, e:\n",
        "#         print ('Exception in code.')\n",
        "#     finally:\n",
        "#     sess.close()\n",
        "# print(sess.run(decoded, feed_dict=feed))\n",
        "  print(sess.run([loss, accuracy, decoded], feed_dict=feed))\n",
        "# with tf.Session() as sess:\n",
        "#   print(sess.run([decoded,_], feed_dict=feed))\n",
        "\n",
        "# In[ ]:\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-41235fe688e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1073\u001b[0m     \u001b[0;31m# Check session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1075\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted to use a closed Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1076\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Attempted to use a closed Session."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "gc2lSJ4ct1Hq",
        "colab_type": "code",
        "outputId": "4556ddb4-e113-45a4-a77b-04c8cb056cd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "cell_type": "code",
      "source": [
        "print(text_to_char_array('She had your dark suit in greasy wash water all year.'))\n",
        "print(np_input_features.shape)\n",
        "print(np_input_features)\n",
        "\n",
        "print(tf.transpose(np_input_features, perm=[2, 0, 1]))\n",
        "print(get_seq_length(tf.transpose(np_input_features, perm=[2, 0, 1])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[19  8  5  0  8  1  4  0 25 15 21 18  0  4  1 18 11  0 19 21  9 20  0  9\n",
            " 14  0  7 18  5  1 19 25  0 23  1 19  8  0 23  1 20  5 18  0  1 12 12  0\n",
            " 25  5  1 18  0]\n",
            "(1, 20, 92)\n",
            "[[[-7.10851527e+02 -7.00449206e+02 -6.69482837e+02 ... -5.54455997e+02\n",
            "   -5.87665631e+02 -6.26060874e+02]\n",
            "  [ 3.39975646e+01  4.15417412e+01  6.26155418e+01 ...  5.90154969e+01\n",
            "    4.25220255e+01  4.31393198e+01]\n",
            "  [ 7.95981059e+00  4.90073931e+00 -5.73262763e+00 ... -6.72576945e+01\n",
            "   -6.42231152e+01 -5.07805881e+01]\n",
            "  ...\n",
            "  [ 5.54676313e+00  5.84615626e+00  7.09184831e+00 ...  7.68070357e+00\n",
            "    1.52800544e+01  1.32020803e+01]\n",
            "  [ 2.49636370e+00 -1.58882614e+00 -4.76932302e+00 ... -1.29986620e+01\n",
            "   -5.76792734e+00 -2.53740854e+00]\n",
            "  [ 4.21450268e+00 -1.73468307e-01 -4.01129040e-01 ...  2.31660020e+00\n",
            "    6.62634403e+00  5.29836962e+00]]]\n",
            "Tensor(\"transpose_5:0\", shape=(92, 1, 20), dtype=float64)\n",
            "Tensor(\"Tile_3:0\", shape=(1,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TFSVYo-VWGyo",
        "colab_type": "code",
        "outputId": "14cf2950-9b09-45cf-fa90-f8c242c92136",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size = 1\n",
        "np_input_labels, np_input_labels_length, np_input_features, np_input_features_length = _load_feature_and_label(['SA1.TXT','SA1.WAV'])\n",
        "print(np_input_labels,np_input_features)\n",
        "print(np_input_labels_length)\n",
        "np_input_labels = np.reshape(np_input_labels, (batch_size, -1))\n",
        "np_input_labels_length = np.reshape(np_input_labels_length, (batch_size))\n",
        "np_input_features = np.reshape(np_input_features, (batch_size, features_in_step, -1))\n",
        "np_input_features_length = np.reshape(np_input_features_length, (batch_size))\n",
        "\n",
        "print(np_input_labels,np_input_features)\n",
        "print(np_input_labels_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([19,  8,  5,  0,  8,  1,  4,  0, 25, 15, 21, 18,  0,  4,  1, 18, 11,\n",
            "        0, 19, 21,  9, 20,  0,  9, 14,  0,  7, 18,  5,  1, 19, 25,  0, 23,\n",
            "        1, 19,  8,  0, 23,  1, 20,  5, 18,  0,  1, 12, 12,  0, 25,  5,  1,\n",
            "       18,  0]), array([[-7.10851527e+02, -7.00449206e+02, -6.69482837e+02, ...,\n",
            "        -5.54455997e+02, -5.87665631e+02, -6.26060874e+02],\n",
            "       [ 3.39975646e+01,  4.15417412e+01,  6.26155418e+01, ...,\n",
            "         5.90154969e+01,  4.25220255e+01,  4.31393198e+01],\n",
            "       [ 7.95981059e+00,  4.90073931e+00, -5.73262763e+00, ...,\n",
            "        -6.72576945e+01, -6.42231152e+01, -5.07805881e+01],\n",
            "       ...,\n",
            "       [ 5.54676313e+00,  5.84615626e+00,  7.09184831e+00, ...,\n",
            "         7.68070357e+00,  1.52800544e+01,  1.32020803e+01],\n",
            "       [ 2.49636370e+00, -1.58882614e+00, -4.76932302e+00, ...,\n",
            "        -1.29986620e+01, -5.76792734e+00, -2.53740854e+00],\n",
            "       [ 4.21450268e+00, -1.73468307e-01, -4.01129040e-01, ...,\n",
            "         2.31660020e+00,  6.62634403e+00,  5.29836962e+00]]))\n",
            "53\n",
            "(array([[19,  8,  5,  0,  8,  1,  4,  0, 25, 15, 21, 18,  0,  4,  1, 18,\n",
            "        11,  0, 19, 21,  9, 20,  0,  9, 14,  0,  7, 18,  5,  1, 19, 25,\n",
            "         0, 23,  1, 19,  8,  0, 23,  1, 20,  5, 18,  0,  1, 12, 12,  0,\n",
            "        25,  5,  1, 18,  0]]), array([[[-7.10851527e+02, -7.00449206e+02, -6.69482837e+02, ...,\n",
            "         -5.54455997e+02, -5.87665631e+02, -6.26060874e+02],\n",
            "        [ 3.39975646e+01,  4.15417412e+01,  6.26155418e+01, ...,\n",
            "          5.90154969e+01,  4.25220255e+01,  4.31393198e+01],\n",
            "        [ 7.95981059e+00,  4.90073931e+00, -5.73262763e+00, ...,\n",
            "         -6.72576945e+01, -6.42231152e+01, -5.07805881e+01],\n",
            "        ...,\n",
            "        [ 5.54676313e+00,  5.84615626e+00,  7.09184831e+00, ...,\n",
            "          7.68070357e+00,  1.52800544e+01,  1.32020803e+01],\n",
            "        [ 2.49636370e+00, -1.58882614e+00, -4.76932302e+00, ...,\n",
            "         -1.29986620e+01, -5.76792734e+00, -2.53740854e+00],\n",
            "        [ 4.21450268e+00, -1.73468307e-01, -4.01129040e-01, ...,\n",
            "          2.31660020e+00,  6.62634403e+00,  5.29836962e+00]]]))\n",
            "[53]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CFgsNNdNkaBv",
        "colab_type": "code",
        "outputId": "9c147484-4a88-4dbc-8973-b0c99c83e9c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "cell_type": "code",
      "source": [
        "path = '/content/drive/My Drive/TIMIT'\n",
        "timit_train_path = '/content/drive/My Drive/TIMIT/TRAIN'\n",
        "timit_test_path = '/content/drive/My Drive/TIMIT/TEST'\n",
        "\n",
        "for d in sorted(os.listdir(timit_train_path)):\n",
        "  for sp in sorted(os.listdir(os.path.join(timit_train_path, d))):\n",
        "    print(os.path.join(timit_train_path, d, sp))\n",
        "    sp_path = os.path.join(timit_train_path, d, sp)\n",
        "    for wave_file in sorted(glob.glob(os.path.join(sp_path, '*.WAV'))):\n",
        "      print(wave_file)\n",
        "    for txt_file in sorted(glob.glob(os.path.join(sp_path, '*.TXT'))):\n",
        "      print(txt_file)\n",
        "    break\n",
        "  break\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/TIMIT/TRAIN/DR1/FCJF0\n",
            "/content/drive/My Drive/TIMIT/TRAIN/DR1/FCJF0/SA1.WAV\n",
            "/content/drive/My Drive/TIMIT/TRAIN/DR1/FCJF0/SA2.WAV\n",
            "/content/drive/My Drive/TIMIT/TRAIN/DR1/FCJF0/SI1027.WAV\n",
            "/content/drive/My Drive/TIMIT/TRAIN/DR1/FCJF0/SI1657.WAV\n",
            "/content/drive/My Drive/TIMIT/TRAIN/DR1/FCJF0/SI648.WAV\n",
            "/content/drive/My Drive/TIMIT/TRAIN/DR1/FCJF0/SX127.WAV\n",
            "/content/drive/My Drive/TIMIT/TRAIN/DR1/FCJF0/SX217.WAV\n",
            "/content/drive/My Drive/TIMIT/TRAIN/DR1/FCJF0/SX307.WAV\n",
            "/content/drive/My Drive/TIMIT/TRAIN/DR1/FCJF0/SX37.WAV\n",
            "/content/drive/My Drive/TIMIT/TRAIN/DR1/FCJF0/SX397.WAV\n",
            "/content/drive/My Drive/TIMIT/TRAIN/DR1/FCJF0/SA1.TXT\n",
            "/content/drive/My Drive/TIMIT/TRAIN/DR1/FCJF0/SA2.TXT\n",
            "/content/drive/My Drive/TIMIT/TRAIN/DR1/FCJF0/SI1027.TXT\n",
            "/content/drive/My Drive/TIMIT/TRAIN/DR1/FCJF0/SI1657.TXT\n",
            "/content/drive/My Drive/TIMIT/TRAIN/DR1/FCJF0/SI648.TXT\n",
            "/content/drive/My Drive/TIMIT/TRAIN/DR1/FCJF0/SX127.TXT\n",
            "/content/drive/My Drive/TIMIT/TRAIN/DR1/FCJF0/SX217.TXT\n",
            "/content/drive/My Drive/TIMIT/TRAIN/DR1/FCJF0/SX307.TXT\n",
            "/content/drive/My Drive/TIMIT/TRAIN/DR1/FCJF0/SX37.TXT\n",
            "/content/drive/My Drive/TIMIT/TRAIN/DR1/FCJF0/SX397.TXT\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}