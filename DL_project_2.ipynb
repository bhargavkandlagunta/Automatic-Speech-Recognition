{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_project.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "bOBjx-E5Gfvw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "9178a382-1877-4d5c-cddb-dbb717d0ffd1"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import librosa\n",
        "import glob\n",
        "import os\n",
        "import string\n",
        "import itertools\n",
        "import threading\n",
        "import codecs\n",
        "import unicodedata\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pickle"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M_UFNw_M-UG9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "path = '/content/drive/My Drive/TIMIT'\n",
        "timit_train_path = '/content/drive/My Drive/TIMIT/TRAIN'\n",
        "timit_test_path = '/content/drive/My Drive/TIMIT/TEST'\n",
        "\n",
        "wav_files = []\n",
        "txt_files = []\n",
        "for d in sorted(os.listdir(timit_train_path)):\n",
        "  for sp in sorted(os.listdir(os.path.join(timit_train_path, d))):\n",
        "    print(os.path.join(timit_train_path, d, sp))\n",
        "    sp_path = os.path.join(timit_train_path, d, sp)\n",
        "    for wave_file in sorted(glob.glob(os.path.join(sp_path, '*.WAV'))):\n",
        "      wav_files.append(wave_file)\n",
        "    for txt_file in sorted(glob.glob(os.path.join(sp_path, '*.TXT'))):\n",
        "      txt_files.append(txt_file)\n",
        "  \n",
        "print(len(wav_files), len(txt_files))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AjyMd3KM-zqh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Loading wave/text data from TIMIT dataset and storing them into pickle files for the first time\n",
        "\n",
        "\n",
        "def load_save_data(wav_files, txt_files):\n",
        "  np_input_labels = []\n",
        "  np_input_labels_length = []\n",
        "  np_input_features = []\n",
        "  np_input_features_length = []\n",
        "\n",
        "  for i in range(len(wav_files)):\n",
        "  #   print(wav_files[i], txt_files[i])\n",
        "    lab, lab_len, feat, feat_len = _load_feature_and_label([txt_files[i], wav_files[i]])\n",
        "    np_input_labels.append(lab)\n",
        "    np_input_labels_length.append(lab_len)\n",
        "    np_input_features.append(feat)\n",
        "    np_input_features_length.append(feat_len)\n",
        "    if(i%100 == 0):\n",
        "      print(i)\n",
        "      \n",
        "  with open('/content/drive/My Drive/TIMIT/wav.pkl', 'wb') as f:\n",
        "  pickle.dump(wav_files, f)\n",
        "  with open('/content/drive/My Drive/TIMIT/txt.pkl', 'wb') as f:\n",
        "    pickle.dump(txt_files, f)\n",
        "  with open('/content/drive/My Drive/TIMIT/np_input_labels.pkl', 'wb') as f:\n",
        "    pickle.dump(np_input_labels, f)\n",
        "  with open('/content/drive/My Drive/TIMIT/np_input_labels_length.pkl', 'wb') as f:\n",
        "    pickle.dump(np_input_labels_length, f)\n",
        "  with open('/content/drive/My Drive/TIMIT/np_input_features.pkl', 'wb') as f:\n",
        "    pickle.dump(np_input_features, f)\n",
        "  with open('/content/drive/My Drive/TIMIT/np_input_features_length.pkl', 'wb') as f:\n",
        "    pickle.dump(np_input_features_length, f)   \n",
        "# load_save_data(wav_files, txt_files)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0cbYR9LE-6bg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Load data from pickle files saved in drive\n",
        "with open('/content/drive/My Drive/TIMIT/wav.pkl', 'rb') as f:\n",
        "  wav_files = pickle.load(f)\n",
        "with open('/content/drive/My Drive/TIMIT/txt.pkl', 'rb') as f:\n",
        "  txt_files = pickle.load(f) \n",
        "with open('/content/drive/My Drive/TIMIT/np_input_labels.pkl', 'rb') as f:\n",
        "  np_input_labels = pickle.load(f)\n",
        "with open('/content/drive/My Drive/TIMIT/np_input_labels_length.pkl', 'rb') as f:\n",
        "  np_input_labels_length = pickle.load(f)  \n",
        "with open('/content/drive/My Drive/TIMIT/np_input_features.pkl', 'rb') as f:\n",
        "  np_input_features = pickle.load(f)\n",
        "with open('/content/drive/My Drive/TIMIT/np_input_features_length.pkl', 'rb') as f:\n",
        "  np_input_features_length = pickle.load(f)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XeSyyk9ys5FW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# In[3]:\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.DEBUG)\n",
        "# In[4]:\n",
        "\n",
        "# Constants\n",
        "SPACE_TOKEN = '<space>'\n",
        "SPACE_INDEX = 0\n",
        "FIRST_INDEX = ord('a') - 1  # 0 is reserved to space\n",
        "\n",
        "def text_to_char_array(original):\n",
        "    r\"\"\"\n",
        "    Given a Python string ``original``, remove unsupported characters, map characters\n",
        "    to integers and return a numpy array representing the processed string.\n",
        "    \"\"\"\n",
        "    # Create list of sentence's words w/spaces replaced by ''\n",
        "    result = ' '.join(original.translate(None, string.punctuation).lower().split())\n",
        "    result = result.replace(\" '\", \"\") # TODO: Deal with this properly\n",
        "    result = result.replace(\"'\", \"\")    # TODO: Deal with this properly\n",
        "    result = result.replace(' ', '  ')\n",
        "    result = result + ' ' #Append spaces at the end of files\n",
        "    result = result.split(' ')\n",
        "\n",
        "    # Tokenize words into letters adding in SPACE_TOKEN where required\n",
        "    result = np.hstack([SPACE_TOKEN if xt == '' else list(xt) for xt in result])\n",
        "    \n",
        "    # Map characters into indicies\n",
        "    result = np.asarray([SPACE_INDEX if xt == SPACE_TOKEN else ord(xt) - FIRST_INDEX for xt in result])\n",
        "    \n",
        "    # Add result to results\n",
        "    return result\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def _get_audio_feature_mfcc(wav_file):\n",
        "    #All wav files are with 8k sampling rate : Taking Fourier representation: 20 ms speech to 20 feature\n",
        "    sample_rate = 16000\n",
        "    # load wave file with sampling rate 8000 which is already known. sr value is important\n",
        "    data, sr = librosa.load(wav_file, mono=True, sr=sample_rate)\n",
        "\n",
        "    #Short First Fourier transform - for every 20 second for 8k sampling rate= 160\n",
        "    mfcc = librosa.feature.mfcc(data, sr=sample_rate, n_mfcc=20)\n",
        "    \n",
        "    return mfcc\n",
        "\n",
        "\n",
        "\n",
        "def _load_feature_and_label(src_list):\n",
        "    txt_file, wav_file = src_list \n",
        "    label = ''\n",
        "    with codecs.open(txt_file, mode = 'rb', encoding=\"utf-8\", errors='ignore') as open_txt_file:\n",
        "        label = unicodedata.normalize(\"NFKD\", open_txt_file.read()).encode(\"ascii\", \"ignore\")\n",
        "        label = text_to_char_array(label)\n",
        "        label = label[8:]\n",
        "    label_len = len(label)\n",
        "\n",
        "    feature = _get_audio_feature_mfcc(wav_file)\n",
        "    feature_len = np.size(feature, 1)\n",
        "\n",
        "    # return result\n",
        "    return label, label_len, feature, feature_len\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# In[5]:\n",
        "\n",
        "###  ctc_label_dense_to_sparse and Taken from https://github.com/mozilla/DeepSpeech  ##########\n",
        "\n",
        "# gather_nd is taken from https://github.com/tensorflow/tensorflow/issues/206#issuecomment-229678962\n",
        "# \n",
        "# Unfortunately we can't just use tf.gather_nd because it does not have gradients\n",
        "# implemented yet, so we need this workaround.\n",
        "#\n",
        "def gather_nd(params, indices, shape):\n",
        "    rank = len(shape)\n",
        "    flat_params = tf.reshape(params, [-1])\n",
        "    multipliers = [reduce(lambda x, y: x*y, shape[i+1:], 1) for i in range(0, rank)]\n",
        "    indices_unpacked = tf.unstack(tf.transpose(indices, [rank - 1] + range(0, rank - 1)))\n",
        "    flat_indices = sum([a*b for a,b in zip(multipliers, indices_unpacked)])\n",
        "    return tf.gather(flat_params, flat_indices)\n",
        "\n",
        "# ctc_label_dense_to_sparse is taken from https://github.com/tensorflow/tensorflow/issues/1742#issuecomment-205291527\n",
        "#\n",
        "# The CTC implementation in TensorFlow needs labels in a sparse representation,\n",
        "# but sparse data and queues don't mix well, so we store padded tensors in the\n",
        "# queue and convert to a sparse representation after dequeuing a batch.\n",
        "\n",
        "def ctc_label_dense_to_sparse(labels, label_lengths, batch_size):\n",
        "    # The second dimension of labels must be equal to the longest label length in the batch\n",
        "    correct_shape_assert = tf.assert_equal(tf.shape(labels)[1], tf.reduce_max(label_lengths))\n",
        "    with tf.control_dependencies([correct_shape_assert]):\n",
        "        labels = tf.identity(labels)\n",
        "\n",
        "    label_shape = tf.shape(labels)\n",
        "    num_batches_tns = tf.stack([label_shape[0]])\n",
        "    max_num_labels_tns = tf.stack([label_shape[1]])\n",
        "    def range_less_than(previous_state, current_input):\n",
        "        return tf.expand_dims(tf.range(label_shape[1]), 0) < current_input\n",
        "\n",
        "    init = tf.cast(tf.fill(max_num_labels_tns, 0), tf.bool)\n",
        "    init = tf.expand_dims(init, 0)\n",
        "    dense_mask = tf.scan(range_less_than, label_lengths, initializer=init, parallel_iterations=1)\n",
        "    dense_mask = dense_mask[:, 0, :]\n",
        "\n",
        "    label_array = tf.reshape(tf.tile(tf.range(0, label_shape[1]), num_batches_tns),\n",
        "          label_shape)\n",
        "    label_ind = tf.boolean_mask(label_array, dense_mask)\n",
        "\n",
        "    batch_array = tf.transpose(tf.reshape(tf.tile(tf.range(0, label_shape[0]), max_num_labels_tns), tf.reverse(label_shape, [0])))\n",
        "    batch_ind = tf.boolean_mask(batch_array, dense_mask)\n",
        "\n",
        "    indices = tf.transpose(tf.reshape(tf.concat([batch_ind, label_ind], 0), [2, -1]))\n",
        "    shape = [batch_size, tf.reduce_max(label_lengths)]\n",
        "    vals_sparse = gather_nd(labels, indices, shape)\n",
        "    \n",
        "    return tf.SparseTensor(tf.to_int64(indices), vals_sparse, tf.to_int64(label_shape))\n",
        "\n",
        "\n",
        "# In[6]:\n",
        "\n",
        "\n",
        "#Input tensor sequence length calculation needed because of convolution changes the length\n",
        "#Take input as shape`[max_time, batch_size, feature]\n",
        "def get_seq_length(input_tensor):\n",
        "    n_items  = tf.slice(tf.shape(input_tensor), [1], [1])\n",
        "    n_steps = tf.slice(tf.shape(input_tensor), [0], [1])\n",
        "    seq_length = tf.tile(n_steps, n_items)\n",
        "    return seq_length\n",
        "\n",
        "\n",
        "#input_tensor is of shape `[max_time, batch_size, input_size]`.\n",
        "#Returns tensor of shape `[max_time, batch_size, input_size]`.\n",
        "def rnn_layer(input_tensor, n_cell_units, dropout, seq_length, batch_size):\n",
        "\n",
        "    lstm_fw_cell = tf.contrib.rnn.BasicLSTMCell(2*n_cell_units, forget_bias=1.0, state_is_tuple=True)\n",
        "    lstm_fw_cell = tf.contrib.rnn.DropoutWrapper(lstm_fw_cell, input_keep_prob=dropout, output_keep_prob=dropout)\n",
        "    \n",
        "    outputs, output_states = tf.nn.dynamic_rnn(cell=lstm_fw_cell, \n",
        "                                               inputs=input_tensor,\n",
        "                                               dtype=tf.float32, \n",
        "                                               time_major=True, \n",
        "                                               sequence_length=seq_length)\n",
        "    \n",
        "    return outputs\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fseGUK2W7MKC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# In[7]:\n",
        "\n",
        "\n",
        "#\n",
        "# hyper parameters\n",
        "#\n",
        "features_in_step = 20\n",
        "# The number of characters in the target language plus one ===>   (<space> + a-z + <one extra>)\n",
        "n_class = 28\n",
        "\n",
        "num_batch = 1\n",
        "num_epoch = 100\n",
        "batch_size = 1\n",
        "\n",
        "####Learning Parameters\n",
        "initial_learning_rate = 0.001\n",
        "momentum = 0.9\n",
        "\n",
        "#RNN Layer\n",
        "n_cell_units = 128\n",
        "dropout = 0.8\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# In[8]:\n",
        "\n",
        "tf.reset_default_graph()\n",
        "input_labels = tf.placeholder(tf.int32, shape=[batch_size,None])\n",
        "input_labels_length = tf.placeholder(tf.int32, shape=[batch_size])\n",
        "input_features = tf.placeholder(tf.float32, shape=[batch_size, features_in_step, None])\n",
        "\n",
        "\n",
        "weights = {\n",
        "    'wr1': tf.Variable(tf.random_normal([2*n_cell_units, n_class], mean=0.1, stddev=1.0))\n",
        "}\n",
        "\n",
        "biases = {\n",
        "    'br1': tf.Variable(tf.random_normal([n_class], mean=0.1, stddev=1.0))\n",
        "}\n",
        "\n",
        "conv_out = input_features\n",
        "\n",
        "#Convert the output to time major of shape`[max_time, batch_size, feature] for RNN layer input\n",
        "conv_out = tf.transpose(conv_out, perm=[2, 0, 1])\n",
        "\n",
        "seq_length = get_seq_length(conv_out)\n",
        "\n",
        "# RNN Layers\n",
        "\n",
        "rnn_output = rnn_layer(conv_out, n_cell_units, dropout, seq_length, batch_size)\n",
        "\n",
        "#Batch size x max_length x n_cell_units.\n",
        "####  This is dense layer for classification -- RNN \n",
        "#ctc network performs softmax layer. in your code, rnn layer is connected to ctc loss layer. \n",
        "#output of rnn layer is internally activated, \n",
        "#so need to add one more hidden layer(as output layer) without activation function, \n",
        "#then add ctc loss layer.\n",
        "prediction = tf.reshape(rnn_output, [-1, 2*n_cell_units])\n",
        "prediction = tf.add(tf.matmul(prediction, weights['wr1']), biases['br1'])\n",
        "prediction = tf.reshape(prediction, [batch_size, -1, n_class])\n",
        "prediction = tf.transpose(prediction, perm=[1, 0, 2])\n",
        "\n",
        "\n",
        "#CTC Layer\n",
        "#Dense to sparse vector conversion\n",
        "sparse_labels = ctc_label_dense_to_sparse(input_labels, input_labels_length, batch_size)\n",
        "\n",
        "#Train\n",
        "loss_from_ctc = tf.nn.ctc_loss(inputs=prediction, labels=sparse_labels, sequence_length=seq_length, time_major=True)\n",
        "loss = tf.reduce_mean(loss_from_ctc)\n",
        "optimizer = tf.train.MomentumOptimizer(initial_learning_rate, momentum).minimize(loss)\n",
        "\n",
        "\n",
        "#Accuracy Check\n",
        "decoded, _ = tf.nn.ctc_beam_search_decoder(inputs=prediction, sequence_length=seq_length, merge_repeated=False)\n",
        "accuracy = tf.reduce_mean(tf.edit_distance(tf.cast(decoded[0], tf.int32), sparse_labels))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ID92R38W7xKV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# In[9]:\n",
        "\n",
        "np_input_labels, np_input_labels_length, np_input_features, np_input_features_length = _load_feature_and_label(['SA1.TXT','SA1.WAV'])\n",
        "\n",
        "np_input_labels = np.reshape(np_input_labels, (batch_size, -1))\n",
        "np_input_labels_length = np.reshape(np_input_labels_length, (batch_size))\n",
        "np_input_features = np.reshape(np_input_features, (batch_size, features_in_step, -1))\n",
        "np_input_features_length = np.reshape(np_input_features_length, (batch_size))\n",
        "\n",
        "print(np_input_features_length)\n",
        "print(np_input_labels_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hAxb_yda7lrK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()\n",
        "init = tf.global_variables_initializer()\n",
        "saver=tf.train.Saver()\n",
        "sess.run(init)\n",
        "\n",
        "feed = {input_labels: np_input_labels, input_labels_length: np_input_labels_length, input_features: np_input_features}\n",
        "\n",
        "for epoch in xrange(num_epoch):\n",
        "    epoch_loss = 0\n",
        "    for step in xrange(num_batch):\n",
        "        print (sess.run([loss, accuracy], feed_dict=feed))\n",
        "        _, c = sess.run([optimizer, loss], feed)\n",
        "        print 'Epoch:', epoch ,'Step:', step, ' Loss:', c\n",
        "        epoch_loss += c\n",
        "    print 'Epoch:', epoch, ' AccLoss:', epoch_loss\n",
        "\n",
        "print 'Finished.'\n",
        "#     except Exception, e:\n",
        "#         print ('Exception in code.')\n",
        "#     finally:\n",
        "#     sess.close()\n",
        "# print(sess.run(decoded, feed_dict=feed))\n",
        "print(sess.run([loss, accuracy, decoded], feed_dict=feed))\n",
        "# In[ ]:\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sNh7SNKzW8ur",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "_load_feature_and_label(['SA1.TXT','SA1.WAV'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gc2lSJ4ct1Hq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(text_to_char_array('She had your dark suit in greasy wash water all year.'))\n",
        "print(np_input_features.shape)\n",
        "print(np_input_features)\n",
        "\n",
        "print(tf.transpose(np_input_features, perm=[2, 0, 1]))\n",
        "print(get_seq_length(tf.transpose(np_input_features, perm=[2, 0, 1])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TFSVYo-VWGyo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 1\n",
        "np_input_labels, np_input_labels_length, np_input_features, np_input_features_length = _load_feature_and_label(['SA1.TXT','SA1.WAV'])\n",
        "print(np_input_labels,np_input_features)\n",
        "print(np_input_labels_length)\n",
        "np_input_labels = np.reshape(np_input_labels, (batch_size, -1))\n",
        "np_input_labels_length = np.reshape(np_input_labels_length, (batch_size))\n",
        "np_input_features = np.reshape(np_input_features, (batch_size, features_in_step, -1))\n",
        "np_input_features_length = np.reshape(np_input_features_length, (batch_size))\n",
        "\n",
        "print(np_input_labels,np_input_features)\n",
        "print(np_input_labels_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S78YDpJIL0oQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Data** \n",
        "Distribution : \n",
        "38+76+76+68+ 70+35+77+22 = 462"
      ]
    }
  ]
}